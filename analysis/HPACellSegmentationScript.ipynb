{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16fb8fcf",
   "metadata": {},
   "source": [
    "PART II: HPA CELL SEGEMENTATION WITH MULTIPLE CHANNELS\n",
    "-------------------------------------\n",
    "\n",
    "NOTES: \n",
    "- SubCell was trained on individual cell crops from the Human Protein Atlas (HPA) SubCellular data, which includes immunofluorescence of 13,147 proteins of interest and 37 different human cell lines. Below are example field of view images for each of the 4 channels in the 2D HPA data: endoplasmic reticulum (yellow), nucleus (blue), microtubules (red), and protein of interest (green).\n",
    "\n",
    "Script Summary: \n",
    "- Matches red/yellow/blue images by basename across folders.\n",
    "- Converts each to grayscale, stacks into a 3-channel (R,Y,B) image.\n",
    "- Auto-downloads nuclei/cell model weights if missing and selects CPU/GPU.\n",
    "- Runs hpacellseg for nuclei and cell segmentation (multi-channel).\n",
    "- Saves nuclei/cell masks (PNG) and raw predictions (NPY) + a summary in analysis/segmentation_results2.\n",
    "\n",
    "*See end of document for detailed script summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32bca7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (0.19.3)\n",
      "Requirement already satisfied: imageio in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: pillow==6.2.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (6.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (1.24.4)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (2.8.8)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from scikit-image) (25.0)\n",
      "Collecting pytorch_zoo\n",
      "  Cloning https://github.com/haoxusci/pytorch_zoo (to revision master) to c:\\users\\bernalr3\\appdata\\local\\temp\\pip-install-6x_qz23l\\pytorch-zoo_e783301dfd18458ab71d757343b91835\n",
      "  Resolved https://github.com/haoxusci/pytorch_zoo to commit e7f30cd9d2e900439f98d250ac309caf03a166b4\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/haoxusci/pytorch_zoo 'C:\\Users\\bernalr3\\AppData\\Local\\Temp\\pip-install-6x_qz23l\\pytorch-zoo_e783301dfd18458ab71d757343b91835'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bernalr3\\appdata\\local\\anaconda3\\envs\\cm4ai\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: install.sh: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#INSTALL PACKAGES, IMAGING DEPS AND CLONES HPA_CELL_SEGMENTATION\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "!pip3 install scikit-image imageio scipy opencv-python pillow==6.2.1\n",
    "!pip install git+https://github.com/haoxusci/pytorch_zoo@master#egg=pytorch_zoo\n",
    "!pip3 install --upgrade torch\n",
    "\n",
    "#!git clone https://github.com/CellProfiling/HPA-Cell-Segmentation.git\n",
    "#%cd HPA-Cell-Segmentation\n",
    "\n",
    "!sh install.sh\n",
    "!python -c \"import hpacellseg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d035c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\analysis\\HPA-Cell-Segmentation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'HPA-Cell-Segmentation' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#Cloning\n",
    "!git clone https://github.com/CellProfiling/HPA-Cell-Segmentation.git\n",
    "%cd HPA-Cell-Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "HPA-Cell-Segmentation Script (multi-channel, RGB->grayscale fix)\n",
    "- Matches red (microtubules), yellow (ER), blue (nuclei) by normalized basename\n",
    "- Converts each channel image to grayscale and stacks as HxWx3 (R,Y,B)\n",
    "- Runs nuclei + cell segmentation and saves masks/predictions\n",
    "\n",
    "Assumes folders:\n",
    "  DATA_ROOT/red, DATA_ROOT/yellow, DATA_ROOT/blue\n",
    "The green channel (protein) is ignored by hpacellseg.\n",
    "\n",
    "Edit the USER PATHS below to match your machine.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "# ------------ Quiet noisy dependency warnings (optional, safe) ------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*multichannel.*\", category=FutureWarning)\n",
    "try:\n",
    "    from torch.serialization import SourceChangeWarning\n",
    "    warnings.filterwarnings(\"ignore\", category=SourceChangeWarning)\n",
    "except Exception:\n",
    "    pass\n",
    "warnings.filterwarnings(\"ignore\", message=\".*weights_only=False.*\", category=FutureWarning)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# ---- NumPy compatibility shim (NumPy >=1.24 removed legacy aliases) ----\n",
    "if \"bool\"  not in np.__dict__: np.bool  = np.bool_\n",
    "if \"int\"   not in np.__dict__: np.int   = np.int_\n",
    "if \"float\" not in np.__dict__: np.float = np.float64\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "# ===================== USER PATHS (update these) =====================\n",
    "HPA_PATH     = Path(r\"C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\HPA-Cell-Segmentation\")\n",
    "DATA_ROOT    = Path(r\"C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\data\")\n",
    "ANALYSIS_DIR = Path(r\"C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\analysis\")\n",
    "# =====================================================================\n",
    "\n",
    "# Try import from installed package; otherwise import from local clone\n",
    "try:\n",
    "    import hpacellseg.cellsegmentator as cellsegmentator\n",
    "    from hpacellseg.utils import label_nuclei, label_cell\n",
    "except ImportError:\n",
    "    if (HPA_PATH / \"hpacellseg\").exists():\n",
    "        sys.path.insert(0, str(HPA_PATH))\n",
    "        import hpacellseg.cellsegmentator as cellsegmentator\n",
    "        from hpacellseg.utils import label_nuclei, label_cell\n",
    "    else:\n",
    "        raise ImportError(\n",
    "            \"Cannot import hpacellseg. Either install it with:\\n\"\n",
    "            f'  pip install -e \"{HPA_PATH}\"\\n'\n",
    "            \"or update HPA_PATH to your clone.\"\n",
    "        )\n",
    "\n",
    "def list_images(folder: Path):\n",
    "    exts = ('.tif', '.tiff', '.png', '.jpg', '.jpeg')\n",
    "    return [p for p in folder.iterdir() if p.is_file() and p.suffix.lower() in exts]\n",
    "\n",
    "# Strip common channel tokens so files can be matched by basename\n",
    "CHANNEL_TOKENS = re.compile(\n",
    "    r'(?i)(?:^|[_\\-\\s])('\n",
    "    r'red|r|microtubules?|mtub|tubulin|tub|'\n",
    "    r'yellow|yel|y|er|reticulum|'\n",
    "    r'blue|b|nuclei|nuc|dapi|dna|'\n",
    "    r'ch(?:an(?:nel)?)?_?\\d{1,2}'\n",
    "    r')(?=$|[_\\-\\s])'\n",
    ")\n",
    "\n",
    "def normalize_key(path: Path):\n",
    "    s = path.stem.lower()\n",
    "    s = CHANNEL_TOKENS.sub('', s)\n",
    "    s = re.sub(r'[_\\-\\s]+', '_', s).strip('_')\n",
    "    return s\n",
    "\n",
    "def natural_key(s: str):\n",
    "    return [int(t) if t.isdigit() else t for t in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def read_gray(path: Path, target_shape=None):\n",
    "    \"\"\"Load image, convert to grayscale (L), return 2D uint8; resize to target_shape=(H,W) if provided.\"\"\"\n",
    "    img = Image.open(path).convert('L')  # force single channel\n",
    "    if target_shape is not None and img.size != (target_shape[1], target_shape[0]):  # PIL size=(W,H)\n",
    "        img = img.resize((target_shape[1], target_shape[0]), resample=Image.BILINEAR)\n",
    "    return np.array(img)\n",
    "\n",
    "def main():\n",
    "    ANALYSIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    out_dir = ANALYSIS_DIR / \"segmentation_results2\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    red_dir    = DATA_ROOT / \"red\"     # microtubules\n",
    "    yellow_dir = DATA_ROOT / \"yellow\"  # ER\n",
    "    blue_dir   = DATA_ROOT / \"blue\"    # nuclei (DAPI)\n",
    "\n",
    "    for d in (red_dir, yellow_dir, blue_dir):\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    red_list    = list_images(red_dir)\n",
    "    yellow_list = list_images(yellow_dir)\n",
    "    blue_list   = list_images(blue_dir)\n",
    "\n",
    "    print(f\"Counts — red: {len(red_list)}, yellow: {len(yellow_list)}, blue: {len(blue_list)}\")\n",
    "\n",
    "    # Build maps by normalized key\n",
    "    def build_map(paths):\n",
    "        m = {}\n",
    "        for p in paths:\n",
    "            k = normalize_key(p)\n",
    "            m.setdefault(k, []).append(p)\n",
    "        return m\n",
    "\n",
    "    red_map    = build_map(red_list)\n",
    "    yellow_map = build_map(yellow_list)\n",
    "    blue_map   = build_map(blue_list)\n",
    "\n",
    "    common_keys = sorted(set(red_map) & set(yellow_map) & set(blue_map), key=natural_key)\n",
    "    if not common_keys:\n",
    "        print(\"No matched (red, yellow, blue) triplets after normalization.\")\n",
    "        # Debug a few keys to help user adjust tokens\n",
    "        for name, m in ((\"red\", red_map), (\"yellow\", yellow_map), (\"blue\", blue_map)):\n",
    "            print(f\"Sample normalized keys for {name}:\", list(m.keys())[:5])\n",
    "        return\n",
    "\n",
    "    print(f\"Matched {len(common_keys)} triplets (red/yellow/blue).\")\n",
    "\n",
    "    # Prepare grayscale arrays and precombined HxWx3 stacks (R=red, Y=yellow, B=blue)\n",
    "    combined_cells = []  # list of HxWx3 uint8\n",
    "    nuc_grays      = []  # list of HxW uint8\n",
    "    stems          = []\n",
    "\n",
    "    for k in common_keys:\n",
    "        r_path = sorted(red_map[k],    key=lambda p: natural_key(p.name))[0]\n",
    "        y_path = sorted(yellow_map[k], key=lambda p: natural_key(p.name))[0]\n",
    "        b_path = sorted(blue_map[k],   key=lambda p: natural_key(p.name))[0]\n",
    "\n",
    "        # Read nuclei first to set target size\n",
    "        b_gray = read_gray(b_path)\n",
    "        r_gray = read_gray(r_path, target_shape=b_gray.shape)\n",
    "        y_gray = read_gray(y_path, target_shape=b_gray.shape)\n",
    "\n",
    "        combo = np.stack([r_gray, y_gray, b_gray], axis=2)  # HxWx3\n",
    "        combined_cells.append(combo)\n",
    "        nuc_grays.append(b_gray)\n",
    "        stems.append(k if k else b_path.stem)\n",
    "\n",
    "    # Model weights (auto-download if missing; delete zero-byte placeholders)\n",
    "    nuclei_model_path = ANALYSIS_DIR / \"nuclei_model.pth\"\n",
    "    cell_model_path   = ANALYSIS_DIR / \"cell_model.pth\"\n",
    "    for p in (nuclei_model_path, cell_model_path):\n",
    "        if p.exists() and p.stat().st_size < 1024:\n",
    "            print(f\"{p.name} looks like a zero-byte placeholder; deleting to trigger re-download.\")\n",
    "            p.unlink()\n",
    "\n",
    "    # Device\n",
    "    try:\n",
    "        import torch\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    except Exception:\n",
    "        device = \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Initialize multi-channel model\n",
    "    print(\"Initializing CellSegmentator (multi_channel_model=True)...\")\n",
    "    segmentator = cellsegmentator.CellSegmentator(\n",
    "        str(nuclei_model_path),\n",
    "        str(cell_model_path),\n",
    "        scale_factor=0.25,\n",
    "        device=device,\n",
    "        padding=True,\n",
    "        multi_channel_model=True\n",
    "    )\n",
    "    print(\"CellSegmentator initialized\")\n",
    "\n",
    "    # Run segmentation\n",
    "    print(\"Running nuclei predictions...\")\n",
    "    nuc_preds  = segmentator.pred_nuclei(nuc_grays)  # pass 2D arrays\n",
    "    print(\"Running cell predictions (precombined RGB stacks)...\")\n",
    "    cell_preds = segmentator.pred_cells(combined_cells, precombined=True)  # <-- key change\n",
    "\n",
    "    # Save results\n",
    "    for i, stem in enumerate(stems, 1):\n",
    "        print(f\"\\nPost-processing {i}/{len(stems)}: {stem}\")\n",
    "\n",
    "        nuc_mask = label_nuclei(nuc_preds[i-1])\n",
    "        nuclei_mask, cell_mask = label_cell(nuc_preds[i-1], cell_preds[i-1])\n",
    "\n",
    "        nuc_mask_png  = out_dir / f\"{stem}_nuclei_mask.png\"\n",
    "        cell_mask_png = out_dir / f\"{stem}_cell_mask.png\"\n",
    "        nuc_pred_npy  = out_dir / f\"{stem}_nuclei_prediction.npy\"\n",
    "        cell_pred_npy = out_dir / f\"{stem}_cell_prediction.npy\"\n",
    "\n",
    "        imageio.imwrite(str(nuc_mask_png),  nuc_mask.astype(np.uint16))\n",
    "        imageio.imwrite(str(cell_mask_png), cell_mask.astype(np.uint16))\n",
    "        np.save(str(nuc_pred_npy),  nuc_preds[i-1])\n",
    "        np.save(str(cell_pred_npy), cell_preds[i-1])\n",
    "\n",
    "        print(f\"  Saved masks: {nuc_mask_png.name}, {cell_mask_png.name}\")\n",
    "\n",
    "    # Summary\n",
    "    summary = out_dir / \"segmentation_summary.txt\"\n",
    "    with open(summary, \"w\") as f:\n",
    "        f.write(\"HPA-Cell-Segmentation Results Summary (multi-channel, grayscale-fixed)\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "        f.write(f\"Matched triplets: {len(stems)}\\n\")\n",
    "        f.write(f\"Data root: {DATA_ROOT}\\nOutput dir: {out_dir}\\n\")\n",
    "        f.write(\"Channels used: red(microtubules)=R, yellow(ER)=Y, blue(nuclei)=B; green ignored.\\n\")\n",
    "        f.write(\"Models: nuclei_model.pth, cell_model.pth\\n\")\n",
    "        f.write(f\"Scale factor: 0.25 | Device: {device.upper()} | Padding: True | Multi-channel: True\\n\")\n",
    "\n",
    "    print(f\"\\nDone. Results in: {out_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "### Results in: C:\\Users\\bernalr3\\OneDrive - UT Health San Antonio\\Archive\\Documents\\CM4AI - WG\\analysis\\segmentation_results2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b51aeb",
   "metadata": {},
   "source": [
    "Detailed Script Summary: \n",
    "1. Sets things up\n",
    "- Points to your repo (HPA_PATH), data root (... \\data), and output folder (... \\analysis\\segmentation_results2).\n",
    "- Silences a few noisy warnings and adds tiny NumPy “compatibility shims” so old code runs on new NumPy.\n",
    "\n",
    "2. Finds and matches your images\n",
    "- Looks inside three folders under data: red/ (microtubules), yellow/ (ER), and blue/ (nuclei/DAPI).\n",
    "- Normalizes filenames (e.g., strips _red, ER, DAPI, ch1, etc.) so it can pair the same field-of-view across channels.\n",
    "- Builds a list of matched triplets (one red + one yellow + one blue per FOV).\n",
    "\n",
    "3. Prepares inputs for the model\n",
    "- Loads each file as grayscale (single channel).\n",
    "- Resizes red and yellow to exactly match the blue image size.\n",
    "- Stacks them into a single 3-channel array in this order: R = red, Y = yellow, B = blue (shape H×W×3).\n",
    "- Also keeps the blue grayscale image alone for nuclei-only segmentation.\n",
    "\n",
    "4. Gets model weights & device\n",
    "- Points to nuclei_model.pth and cell_model.pth in your analysis folder; if a file is a tiny placeholder, deletes it so the package will auto-download it.\n",
    "- Chooses CUDA if available, otherwise CPU.\n",
    "\n",
    "5. Initializes the HPA segmentator\n",
    "- Creates CellSegmentator(..., multi_channel_model=True) so it can use the 3-channel cell model.\n",
    "\n",
    "6. Runs segmentation\n",
    "- Nuclei: calls pred_nuclei(...) on the blue (nuclei) grayscale images.\n",
    "- Cells: calls pred_cells(precombined=True) on the stacked R/Y/B arrays to get whole-cell predictions.\n",
    "\n",
    "7. Post-processes & saves results\n",
    "- Converts raw nuclei predictions to a labeled nuclei mask with label_nuclei(...).\n",
    "- Combines nuclei + cell predictions to get a labeled cell mask with label_cell(...).\n",
    "- Saves:\n",
    "    *_nuclei_mask.png and *_cell_mask.png (PNG label images)\n",
    "    *_nuclei_prediction.npy and *_cell_prediction.npy (raw model outputs)\n",
    "\n",
    "- Writes a summary text file listing what was processed and the settings used.\n",
    "\n",
    "8. What it ignores\n",
    "- The green channel (protein of interest) isn’t used by hpacellseg for segmentation, so the script doesn’t load it.\n",
    "\n",
    "9. Where results go\n",
    "- Everything lands in:\n",
    "    ...\\CM4AI - WG\\analysis\\segmentation_results2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cm4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
